{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.1"},"colab":{"provenance":[],"machine_shape":"hm","gpuClass":"premium"},"accelerator":"GPU","gpuClass":"premium","widgets":{"application/vnd.jupyter.widget-state+json":{"9fed146e3e6f449795c1b4ada8937b65":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_fbd7ef10600243769cf649e5998aa042","IPY_MODEL_dae0ae3edb87414199336bc66efe2b9f","IPY_MODEL_3fd3174160d54618bb6a9eac1a8cf065"],"layout":"IPY_MODEL_2f1a105df2ac4268bdca1ad394263d42"}},"fbd7ef10600243769cf649e5998aa042":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a2c60877d66e42a3b84154c625d3bd18","placeholder":"​","style":"IPY_MODEL_c1c6ea4be0e74440bf01cebf59bd9936","value":"Downloading (…)zer_78b3253a26.model: 100%"}},"dae0ae3edb87414199336bc66efe2b9f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a084df3445e14c73bd87b9f5d09183c2","max":371391,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e933229286b44cf380f2d6b799cc71b1","value":371391}},"3fd3174160d54618bb6a9eac1a8cf065":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0d2f95582a94432da0ecda7bc02cbb96","placeholder":"​","style":"IPY_MODEL_a760cd48d94f4da39226bead900b23ee","value":" 371k/371k [00:00&lt;00:00, 6.97MB/s]"}},"2f1a105df2ac4268bdca1ad394263d42":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a2c60877d66e42a3b84154c625d3bd18":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c1c6ea4be0e74440bf01cebf59bd9936":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a084df3445e14c73bd87b9f5d09183c2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e933229286b44cf380f2d6b799cc71b1":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0d2f95582a94432da0ecda7bc02cbb96":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a760cd48d94f4da39226bead900b23ee":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"82170a539c114485b1b6eb20fe20e27b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_feef82886dcf448a9c5e33b078a6c40f","IPY_MODEL_82b84e35c9e641708cae6bcffdb3b551","IPY_MODEL_f8aab7d9c4374897913a9977dabc51b8"],"layout":"IPY_MODEL_54825f9a42824179aaec4fccb293c4de"}},"feef82886dcf448a9c5e33b078a6c40f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_88a882014e3945df9d9648518ff0e473","placeholder":"​","style":"IPY_MODEL_9abaafec3d9e464586fc1bbc33a77425","value":"Downloading (…)solve/main/vocab.txt: 100%"}},"82b84e35c9e641708cae6bcffdb3b551":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ffda63d9bd724bb58df14b4d31a61e38","max":77779,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2d06b5359c4f4c298af56b7e5cba29f1","value":77779}},"f8aab7d9c4374897913a9977dabc51b8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_21649ad75ae0430cab79dca491df9c30","placeholder":"​","style":"IPY_MODEL_2dedfe9f115a4c89b6857c928cb97f07","value":" 77.8k/77.8k [00:00&lt;00:00, 2.76MB/s]"}},"54825f9a42824179aaec4fccb293c4de":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"88a882014e3945df9d9648518ff0e473":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9abaafec3d9e464586fc1bbc33a77425":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ffda63d9bd724bb58df14b4d31a61e38":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2d06b5359c4f4c298af56b7e5cba29f1":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"21649ad75ae0430cab79dca491df9c30":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2dedfe9f115a4c89b6857c928cb97f07":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"25c4b2f5a3584acf9478000c4ba9aa09":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_35d5862c297f43da874b13e6e217f237","IPY_MODEL_0630bdb0daf54fcb9f9dd6b8c3431365","IPY_MODEL_690183cd85c24aa2b07a73dea2719f18"],"layout":"IPY_MODEL_f47b1d1e59f14c8aaa9c6b5f2c01fd57"}},"35d5862c297f43da874b13e6e217f237":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_eb458838272e4a868d767cc02983131f","placeholder":"​","style":"IPY_MODEL_a94d7d3b5a3c4713875f682ea4809de0","value":"Downloading (…)okenizer_config.json: 100%"}},"0630bdb0daf54fcb9f9dd6b8c3431365":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e73d3a01810a4675bfbbf857ec0bbcfd","max":51,"min":0,"orientation":"horizontal","style":"IPY_MODEL_91a04c9b76fa49399329ae84d792e05b","value":51}},"690183cd85c24aa2b07a73dea2719f18":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ad429c9685da4abb944d00fba160053a","placeholder":"​","style":"IPY_MODEL_5d118e4fe9a2461b817d553985d16745","value":" 51.0/51.0 [00:00&lt;00:00, 3.83kB/s]"}},"f47b1d1e59f14c8aaa9c6b5f2c01fd57":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eb458838272e4a868d767cc02983131f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a94d7d3b5a3c4713875f682ea4809de0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e73d3a01810a4675bfbbf857ec0bbcfd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"91a04c9b76fa49399329ae84d792e05b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ad429c9685da4abb944d00fba160053a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5d118e4fe9a2461b817d553985d16745":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c13e0c66ea144a23a535ad875b64584a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f885b0ea40e641c9bab909abcecb921e","IPY_MODEL_3dcc14a080c84bc5826812ef8e57d04c","IPY_MODEL_25abd1d937ce4a15b7090b9106571640"],"layout":"IPY_MODEL_3b83e6ee8a1142eb8c11635e79b6fba5"}},"f885b0ea40e641c9bab909abcecb921e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_17969b187c924957b817b132c47aea01","placeholder":"​","style":"IPY_MODEL_557f8737e80a4d23aadbe995b39f554e","value":"Downloading (…)lve/main/config.json: 100%"}},"3dcc14a080c84bc5826812ef8e57d04c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e57caedbd4da489e966d044cc516a25c","max":426,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9347e85c45c644619a6a094b3371728d","value":426}},"25abd1d937ce4a15b7090b9106571640":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_aeb99cd7b5974ac5aacf85b09fed17c8","placeholder":"​","style":"IPY_MODEL_7de806da3db449a99679b0a7e311a765","value":" 426/426 [00:00&lt;00:00, 31.8kB/s]"}},"3b83e6ee8a1142eb8c11635e79b6fba5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"17969b187c924957b817b132c47aea01":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"557f8737e80a4d23aadbe995b39f554e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e57caedbd4da489e966d044cc516a25c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9347e85c45c644619a6a094b3371728d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"aeb99cd7b5974ac5aacf85b09fed17c8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7de806da3db449a99679b0a7e311a765":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bf2fcb0b23f74871b15f7134824e5092":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a081636ab6074898be3365a2fb442ec5","IPY_MODEL_dce2aa48fc2141f4bd109c42927eb673","IPY_MODEL_fbcf51736ddd49648a35e9111f020c3b"],"layout":"IPY_MODEL_80065dd280b44475bfb606aa1d0829a4"}},"a081636ab6074898be3365a2fb442ec5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1cbe0671738f4d2da20411f0c7b1f3d0","placeholder":"​","style":"IPY_MODEL_a52661fc69ed43d8abd6211b71dcbea4","value":"Downloading pytorch_model.bin: 100%"}},"dce2aa48fc2141f4bd109c42927eb673":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_90354e1d2dff4754a728d7bd6fed0554","max":368792146,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1fafd8dcf5cd4791b8ea0d85eb3c1e0c","value":368792146}},"fbcf51736ddd49648a35e9111f020c3b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a44fdf2dd6294447b2bdaa90e27fdb0b","placeholder":"​","style":"IPY_MODEL_66fa54fd03e343408df83def7fe39f51","value":" 369M/369M [00:03&lt;00:00, 96.8MB/s]"}},"80065dd280b44475bfb606aa1d0829a4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1cbe0671738f4d2da20411f0c7b1f3d0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a52661fc69ed43d8abd6211b71dcbea4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"90354e1d2dff4754a728d7bd6fed0554":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1fafd8dcf5cd4791b8ea0d85eb3c1e0c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a44fdf2dd6294447b2bdaa90e27fdb0b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"66fa54fd03e343408df83def7fe39f51":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"cFEpHz9q2TkF"},"source":["# ChildBERT_ADSCDS"]},{"cell_type":"code","metadata":{"id":"VPmd3h1VZUs8"},"source":["##Parameter setting\n","setEpoch = 30\n","setLearningRate = [0.001, 0.0005, 0.0001]\n","setBatch = [16, 32, 64]\n","setMaxLength = [64, 128, 256]\n","setEpsilon = 1e-8\n","setSeed = 42\n","labelNumber = 2\n","setTry = 5 #30"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9LAZ1CSc3Bm_","executionInfo":{"status":"ok","timestamp":1682310622961,"user_tz":-540,"elapsed":13708,"user":{"displayName":"Seongmin Mun","userId":"17295717412647902050"}},"outputId":"05fcc360-324e-4b39-b667-1d83c7c2387f"},"source":["import tensorflow as tf\n","\n","# Get the GPU device name.\n","device_name = tf.test.gpu_device_name()\n","\n","# The device name should look like the following:\n","if device_name == '/device:GPU:0':\n","    print('Found GPU at: {}'.format(device_name))\n","else:\n","    raise SystemError('GPU device not found')\n","\n","import torch\n","\n","# If there's a GPU available...\n","if torch.cuda.is_available():\n","\n","    # Tell PyTorch to use the GPU.\n","    device = torch.device(\"cuda\")\n","\n","    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n","\n","    print('We will use the GPU:', torch.cuda.get_device_name(0))\n","\n","# If not...\n","else:\n","    print('No GPU available, using the CPU instead.')\n","    device = torch.device(\"cpu\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Found GPU at: /device:GPU:0\n","There are 1 GPU(s) available.\n","We will use the GPU: NVIDIA A100-SXM4-40GB\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SEAoJWbt2TkL","executionInfo":{"status":"ok","timestamp":1682310657061,"user_tz":-540,"elapsed":31348,"user":{"displayName":"Seongmin Mun","userId":"17295717412647902050"}},"outputId":"22e14eec-6bf4-4cb2-c27d-7e39d9f3c1cf"},"source":["!pip install transformers\n","!pip install kobert_transformers\n","!pip install tensorflow\n","!pip install keras\n","!pip install keras_preprocessing\n","!pip install sentencepiece"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.28.1-py3-none-any.whl (7.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m56.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2022.10.31)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.11.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (1.22.4)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (6.0)\n","Collecting huggingface-hub<1.0,>=0.11.0\n","  Downloading huggingface_hub-0.13.4-py3-none-any.whl (200 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.1/200.1 kB\u001b[0m \u001b[31m25.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting tokenizers!=0.11.3,<0.14,>=0.11.1\n","  Downloading tokenizers-0.13.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m95.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (23.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers) (2.27.1)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers) (4.65.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2022.12.7)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (3.4)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2.0.12)\n","Installing collected packages: tokenizers, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.13.4 tokenizers-0.13.3 transformers-4.28.1\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting kobert_transformers\n","  Downloading kobert_transformers-0.5.1-py3-none-any.whl (12 kB)\n","Requirement already satisfied: transformers<5,>=3 in /usr/local/lib/python3.9/dist-packages (from kobert_transformers) (4.28.1)\n","Requirement already satisfied: torch>=1.1.0 in /usr/local/lib/python3.9/dist-packages (from kobert_transformers) (2.0.0+cu118)\n","Collecting sentencepiece>=0.1.91\n","  Downloading sentencepiece-0.1.98-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch>=1.1.0->kobert_transformers) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from torch>=1.1.0->kobert_transformers) (1.11.1)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.9/dist-packages (from torch>=1.1.0->kobert_transformers) (2.0.0)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from torch>=1.1.0->kobert_transformers) (3.1.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (from torch>=1.1.0->kobert_transformers) (3.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from torch>=1.1.0->kobert_transformers) (3.11.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch>=1.1.0->kobert_transformers) (3.25.2)\n","Requirement already satisfied: lit in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch>=1.1.0->kobert_transformers) (16.0.1)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.9/dist-packages (from transformers<5,>=3->kobert_transformers) (0.13.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers<5,>=3->kobert_transformers) (4.65.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers<5,>=3->kobert_transformers) (2.27.1)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers<5,>=3->kobert_transformers) (23.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers<5,>=3->kobert_transformers) (2022.10.31)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.9/dist-packages (from transformers<5,>=3->kobert_transformers) (0.13.4)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers<5,>=3->kobert_transformers) (6.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers<5,>=3->kobert_transformers) (1.22.4)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->torch>=1.1.0->kobert_transformers) (2.1.2)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers<5,>=3->kobert_transformers) (2022.12.7)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers<5,>=3->kobert_transformers) (3.4)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->transformers<5,>=3->kobert_transformers) (2.0.12)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers<5,>=3->kobert_transformers) (1.26.15)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.9/dist-packages (from sympy->torch>=1.1.0->kobert_transformers) (1.3.0)\n","Installing collected packages: sentencepiece, kobert_transformers\n","Successfully installed kobert_transformers-0.5.1 sentencepiece-0.1.98\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: tensorflow in /usr/local/lib/python3.9/dist-packages (2.12.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (0.2.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (1.53.0)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (3.8.0)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (0.32.0)\n","Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (1.14.1)\n","Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (0.4.8)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from tensorflow) (67.6.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from tensorflow) (23.1)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (4.5.0)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (16.0.0)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (3.3.0)\n","Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (2.12.0)\n","Requirement already satisfied: keras<2.13,>=2.12.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (2.12.0)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (1.16.0)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (1.4.0)\n","Requirement already satisfied: tensorboard<2.13,>=2.12 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (2.12.2)\n","Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (23.3.3)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (2.2.0)\n","Requirement already satisfied: numpy<1.24,>=1.22 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (1.22.4)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (3.20.3)\n","Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (0.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (1.6.3)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.9/dist-packages (from astunparse>=1.6.0->tensorflow) (0.40.0)\n","Requirement already satisfied: scipy>=1.7 in /usr/local/lib/python3.9/dist-packages (from jax>=0.3.15->tensorflow) (1.10.1)\n","Requirement already satisfied: ml-dtypes>=0.0.3 in /usr/local/lib/python3.9/dist-packages (from jax>=0.3.15->tensorflow) (0.1.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (3.4.3)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.27.1)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (0.7.0)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (1.8.1)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.17.3)\n","Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (1.0.0)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.2.3)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (4.9)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (5.3.0)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.2.8)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.9/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow) (1.3.1)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.9/dist-packages (from markdown>=2.6.8->tensorboard<2.13,>=2.12->tensorflow) (6.4.1)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (3.4)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (1.26.15)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.9/dist-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow) (2.1.2)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.13,>=2.12->tensorflow) (3.15.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.9/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.4.8)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.9/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow) (3.2.2)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: keras in /usr/local/lib/python3.9/dist-packages (2.12.0)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting keras_preprocessing\n","  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.9/dist-packages (from keras_preprocessing) (1.22.4)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.9/dist-packages (from keras_preprocessing) (1.16.0)\n","Installing collected packages: keras_preprocessing\n","Successfully installed keras_preprocessing-1.1.2\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.9/dist-packages (0.1.98)\n"]}]},{"cell_type":"code","metadata":{"id":"Hv2_wH8A2TkN"},"source":["import tensorflow as tf\n","import torch\n","\n","from transformers import BertTokenizer\n","from transformers import BertForSequenceClassification, AdamW, BertConfig\n","from transformers import get_linear_schedule_with_warmup\n","from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n","# from keras.preprocessing.sequence import pad_sequences\n","from keras_preprocessing.sequence import pad_sequences\n","from sklearn.model_selection import train_test_split\n","\n","import pandas as pd\n","import numpy as np\n","import random\n","import time\n","import datetime\n","import sentencepiece as spm"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"X3aCo4t22ahB","executionInfo":{"status":"ok","timestamp":1682310676544,"user_tz":-540,"elapsed":14292,"user":{"displayName":"Seongmin Mun","userId":"17295717412647902050"}},"outputId":"a7ca3fba-5167-4536-aed1-3d69998ea44d"},"source":["# Mount Google Drive to this Notebook instance.\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"id":"o-Ua-ci84w0f"},"source":["# coding=utf-8\n","# Copyright 2018 Google AI, Google Brain and Carnegie Mellon University Authors and the HuggingFace Inc. team and Jangwon Park\n","#\n","# Licensed under the Apache License, Version 2.0 (the \"License\");\n","# you may not use this file except in compliance with the License.\n","# You may obtain a copy of the License at\n","#\n","#     http://www.apache.org/licenses/LICENSE-2.0\n","#\n","# Unless required by applicable law or agreed to in writing, software\n","# distributed under the License is distributed on an \"AS IS\" BASIS,\n","# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","# See the License for the specific language governing permissions and\n","# limitations under the License.\n","\"\"\" Tokenization classes for KoBert model.\"\"\"\n","\n","\n","import logging\n","import os\n","import unicodedata\n","from shutil import copyfile\n","\n","from transformers import PreTrainedTokenizer\n","\n","\n","logger = logging.getLogger(__name__)\n","\n","VOCAB_FILES_NAMES = {\"vocab_file\": \"tokenizer_78b3253a26.model\",\n","                     \"vocab_txt\": \"vocab.txt\"}\n","\n","PRETRAINED_VOCAB_FILES_MAP = {\n","    \"vocab_file\": {\n","        \"monologg/kobert\": \"https://s3.amazonaws.com/models.huggingface.co/bert/monologg/kobert/tokenizer_78b3253a26.model\",\n","        \"monologg/kobert-lm\": \"https://s3.amazonaws.com/models.huggingface.co/bert/monologg/kobert-lm/tokenizer_78b3253a26.model\",\n","        \"monologg/distilkobert\": \"https://s3.amazonaws.com/models.huggingface.co/bert/monologg/distilkobert/tokenizer_78b3253a26.model\"\n","    },\n","    \"vocab_txt\": {\n","        \"monologg/kobert\": \"https://s3.amazonaws.com/models.huggingface.co/bert/monologg/kobert/vocab.txt\",\n","        \"monologg/kobert-lm\": \"https://s3.amazonaws.com/models.huggingface.co/bert/monologg/kobert-lm/vocab.txt\",\n","        \"monologg/distilkobert\": \"https://s3.amazonaws.com/models.huggingface.co/bert/monologg/distilkobert/vocab.txt\"\n","    }\n","}\n","\n","PRETRAINED_POSITIONAL_EMBEDDINGS_SIZES = {\n","    \"monologg/kobert\": 512,\n","    \"monologg/kobert-lm\": 512,\n","    \"monologg/distilkobert\": 512\n","}\n","\n","PRETRAINED_INIT_CONFIGURATION = {\n","    \"monologg/kobert\": {\"do_lower_case\": False},\n","    \"monologg/kobert-lm\": {\"do_lower_case\": False},\n","    \"monologg/distilkobert\": {\"do_lower_case\": False}\n","}\n","\n","SPIECE_UNDERLINE = u'▁'\n","\n","\n","class KoBertTokenizer(PreTrainedTokenizer):\n","    \"\"\"\n","        SentencePiece based tokenizer. Peculiarities:\n","            - requires `SentencePiece <https://github.com/google/sentencepiece>`_\n","    \"\"\"\n","    vocab_files_names = VOCAB_FILES_NAMES\n","    pretrained_vocab_files_map = PRETRAINED_VOCAB_FILES_MAP\n","    pretrained_init_configuration = PRETRAINED_INIT_CONFIGURATION\n","    max_model_input_sizes = PRETRAINED_POSITIONAL_EMBEDDINGS_SIZES\n","\n","    def __init__(\n","            self,\n","            vocab_file,\n","            vocab_txt,\n","            do_lower_case=False,\n","            remove_space=True,\n","            keep_accents=False,\n","            unk_token=\"[UNK]\",\n","            sep_token=\"[SEP]\",\n","            pad_token=\"[PAD]\",\n","            cls_token=\"[CLS]\",\n","            mask_token=\"[MASK]\",\n","            **kwargs):\n","        super().__init__(\n","            unk_token=unk_token,\n","            sep_token=sep_token,\n","            pad_token=pad_token,\n","            cls_token=cls_token,\n","            mask_token=mask_token,\n","            **kwargs\n","        )\n","\n","        # Build vocab\n","        self.token2idx = dict()\n","        self.idx2token = []\n","        with open(vocab_txt, 'r', encoding='utf-8') as f:\n","            for idx, token in enumerate(f):\n","                token = token.strip()\n","                self.token2idx[token] = idx\n","                self.idx2token.append(token)\n","\n","        try:\n","            import sentencepiece as spm\n","        except ImportError:\n","            logger.warning(\"You need to install SentencePiece to use KoBertTokenizer: https://github.com/google/sentencepiece\"\n","                           \"pip install sentencepiece\")\n","\n","        self.do_lower_case = do_lower_case\n","        self.remove_space = remove_space\n","        self.keep_accents = keep_accents\n","        self.vocab_file = vocab_file\n","        self.vocab_txt = vocab_txt\n","\n","        self.sp_model = spm.SentencePieceProcessor()\n","        self.sp_model.Load(vocab_file)\n","\n","    @property\n","    def vocab_size(self):\n","        return len(self.idx2token)\n","\n","    def get_vocab(self):\n","        return dict(self.token2idx, **self.added_tokens_encoder)\n","\n","    def __getstate__(self):\n","        state = self.__dict__.copy()\n","        state[\"sp_model\"] = None\n","        return state\n","\n","    def __setstate__(self, d):\n","        self.__dict__ = d\n","        try:\n","            import sentencepiece as spm\n","        except ImportError:\n","            logger.warning(\"You need to install SentencePiece to use KoBertTokenizer: https://github.com/google/sentencepiece\"\n","                           \"pip install sentencepiece\")\n","        self.sp_model = spm.SentencePieceProcessor()\n","        self.sp_model.Load(self.vocab_file)\n","\n","    def preprocess_text(self, inputs):\n","        if self.remove_space:\n","            outputs = \" \".join(inputs.strip().split())\n","        else:\n","            outputs = inputs\n","        outputs = outputs.replace(\"``\", '\"').replace(\"''\", '\"')\n","\n","        if not self.keep_accents:\n","            outputs = unicodedata.normalize('NFKD', outputs)\n","            outputs = \"\".join([c for c in outputs if not unicodedata.combining(c)])\n","        if self.do_lower_case:\n","            outputs = outputs.lower()\n","\n","        return outputs\n","\n","    def _tokenize(self, text, return_unicode=True, sample=False):\n","        \"\"\" Tokenize a string. \"\"\"\n","        text = self.preprocess_text(text)\n","\n","        if not sample:\n","            pieces = self.sp_model.EncodeAsPieces(text)\n","        else:\n","            pieces = self.sp_model.SampleEncodeAsPieces(text, 64, 0.1)\n","        new_pieces = []\n","        for piece in pieces:\n","            if len(piece) > 1 and piece[-1] == str(\",\") and piece[-2].isdigit():\n","                cur_pieces = self.sp_model.EncodeAsPieces(piece[:-1].replace(SPIECE_UNDERLINE, \"\"))\n","                if piece[0] != SPIECE_UNDERLINE and cur_pieces[0][0] == SPIECE_UNDERLINE:\n","                    if len(cur_pieces[0]) == 1:\n","                        cur_pieces = cur_pieces[1:]\n","                    else:\n","                        cur_pieces[0] = cur_pieces[0][1:]\n","                cur_pieces.append(piece[-1])\n","                new_pieces.extend(cur_pieces)\n","            else:\n","                new_pieces.append(piece)\n","\n","        return new_pieces\n","\n","    def _convert_token_to_id(self, token):\n","        \"\"\" Converts a token (str/unicode) in an id using the vocab. \"\"\"\n","        return self.token2idx.get(token, self.token2idx[self.unk_token])\n","\n","    def _convert_id_to_token(self, index, return_unicode=True):\n","        \"\"\"Converts an index (integer) in a token (string/unicode) using the vocab.\"\"\"\n","        return self.idx2token[index]\n","\n","    def convert_tokens_to_string(self, tokens):\n","        \"\"\"Converts a sequence of tokens (strings for sub-words) in a single string.\"\"\"\n","        out_string = \"\".join(tokens).replace(SPIECE_UNDERLINE, \" \").strip()\n","        return out_string\n","\n","    def build_inputs_with_special_tokens(self, token_ids_0, token_ids_1=None):\n","        \"\"\"\n","        Build model inputs from a sequence or a pair of sequence for sequence classification tasks\n","        by concatenating and adding special tokens.\n","        A KoBERT sequence has the following format:\n","            single sequence: [CLS] X [SEP]\n","            pair of sequences: [CLS] A [SEP] B [SEP]\n","        \"\"\"\n","        if token_ids_1 is None:\n","            return [self.cls_token_id] + token_ids_0 + [self.sep_token_id]\n","        cls = [self.cls_token_id]\n","        sep = [self.sep_token_id]\n","        return cls + token_ids_0 + sep + token_ids_1 + sep\n","\n","    def get_special_tokens_mask(self, token_ids_0, token_ids_1=None, already_has_special_tokens=False):\n","        \"\"\"\n","        Retrieves sequence ids from a token list that has no special tokens added. This method is called when adding\n","        special tokens using the tokenizer ``prepare_for_model`` or ``encode_plus`` methods.\n","        Args:\n","            token_ids_0: list of ids (must not contain special tokens)\n","            token_ids_1: Optional list of ids (must not contain special tokens), necessary when fetching sequence ids\n","                for sequence pairs\n","            already_has_special_tokens: (default False) Set to True if the token list is already formated with\n","                special tokens for the model\n","        Returns:\n","            A list of integers in the range [0, 1]: 0 for a special token, 1 for a sequence token.\n","        \"\"\"\n","\n","        if already_has_special_tokens:\n","            if token_ids_1 is not None:\n","                raise ValueError(\n","                    \"You should not supply a second sequence if the provided sequence of \"\n","                    \"ids is already formated with special tokens for the model.\"\n","                )\n","            return list(map(lambda x: 1 if x in [self.sep_token_id, self.cls_token_id] else 0, token_ids_0))\n","\n","        if token_ids_1 is not None:\n","            return [1] + ([0] * len(token_ids_0)) + [1] + ([0] * len(token_ids_1)) + [1]\n","        return [1] + ([0] * len(token_ids_0)) + [1]\n","\n","    def create_token_type_ids_from_sequences(self, token_ids_0, token_ids_1=None):\n","        \"\"\"\n","        Creates a mask from the two sequences passed to be used in a sequence-pair classification task.\n","        A KoBERT sequence pair mask has the following format:\n","        0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1\n","        | first sequence    | second sequence\n","        if token_ids_1 is None, only returns the first portion of the mask (0's).\n","        \"\"\"\n","        sep = [self.sep_token_id]\n","        cls = [self.cls_token_id]\n","        if token_ids_1 is None:\n","            return len(cls + token_ids_0 + sep) * [0]\n","        return len(cls + token_ids_0 + sep) * [0] + len(token_ids_1 + sep) * [1]\n","\n","    def save_vocabulary(self, save_directory):\n","        \"\"\" Save the sentencepiece vocabulary (copy original file) and special tokens file\n","            to a directory.\n","        \"\"\"\n","        if not os.path.isdir(save_directory):\n","            logger.error(\"Vocabulary path ({}) should be a directory\".format(save_directory))\n","            return\n","\n","        # 1. Save sentencepiece model\n","        out_vocab_model = os.path.join(save_directory, VOCAB_FILES_NAMES[\"vocab_file\"])\n","\n","        if os.path.abspath(self.vocab_file) != os.path.abspath(out_vocab_model):\n","            copyfile(self.vocab_file, out_vocab_model)\n","\n","        # 2. Save vocab.txt\n","        index = 0\n","        out_vocab_txt = os.path.join(save_directory, VOCAB_FILES_NAMES[\"vocab_txt\"])\n","        with open(out_vocab_txt, \"w\", encoding=\"utf-8\") as writer:\n","            for token, token_index in sorted(self.token2idx.items(), key=lambda kv: kv[1]):\n","                if index != token_index:\n","                    logger.warning(\n","                        \"Saving vocabulary to {}: vocabulary indices are not consecutive.\"\n","                        \" Please check that the vocabulary is not corrupted!\".format(out_vocab_txt)\n","                    )\n","                    index = token_index\n","                writer.write(token + \"\\n\")\n","                index += 1\n","\n","        return out_vocab_model, out_vocab_txt"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","# 본격적인 학습 시작\n","setLearningRate = [0.0001]\n","for currentLearningRate in setLearningRate:\n","  for currentBatch in setBatch:\n","    for currentMaxLength in setMaxLength:\n","      for currentTry in range(0,setTry):\n","\n","        import pandas as pd\n","        import random\n","\n","\n","        # 말뭉치를 랜덤으로 생성하는 함수\n","        def RandomSelect(dataList):\n","\n","          #5000개 데이터 추출\n","          dataListFT = []\n","          for i in range(0, 5000):\n","            randomNum = random.randrange(0, len(dataList))\n","            dataListFT.append(dataList[randomNum])\n","            del dataList[randomNum]\n","\n","          testNum = 500 #round(len(dataListFT) * 0.1)\n","          testList = []\n","          for i in range(0, testNum):\n","            randomNum = random.randrange(0, len(dataListFT))\n","            testList.append(dataListFT[randomNum])\n","            del dataListFT[randomNum]\n","          trainList = dataListFT\n","          return testList, trainList\n","\n","        # 말뭉치 생성하기\n","        #ADS = 0\n","        NIKL_DIALOGUEDir = \"../../Data/NIKL_DIALOGUE/NIKL_DIALOGUE_equalSize_WO_OWU.txt\"\n","\n","        NIKL_DIALOGUEfr = open(NIKL_DIALOGUEDir, 'r')\n","        contentsNIKL_DIALOGUE = NIKL_DIALOGUEfr.readlines()\n","        NIKL_DIALOGUEfr.close()\n","\n","        ADSList = []\n","        for content in contentsNIKL_DIALOGUE:\n","          content = content.replace(\"\\n\",\"\")\n","          contentText = content.split(\",\")[1]\n","          ADSList.append(\"0,\"+contentText)\n","\n","        testADS, trainADS = RandomSelect(ADSList)\n","\n","\n","        #CDS = 1\n","        CHILDESDir = \"../../Data/CHILDES/CHILDES_All_WO_OWU.txt\"\n","\n","        CHILDESfr = open(CHILDESDir, 'r')\n","        contentsCHILDES = CHILDESfr.readlines()\n","        CHILDESfr.close()\n","\n","        CDSList = []\n","        for content in contentsCHILDES:\n","          content = content.replace(\"\\n\",\"\")\n","          contentText = content.split(\",\")[1]\n","          CDSList.append(\"1,\"+contentText)\n","\n","        testCDS, trainCDS = RandomSelect(CDSList)\n","\n","\n","\n","        #Test데이터 생성하기\n","        testSet = testADS + testCDS\n","\n","        test = pd.DataFrame(columns=('Label', 'Sentence'))\n","        i = 0\n","        for content in testSet:\n","          infos = content.split(\",\")\n","          label = int(infos[0])\n","          sentence = infos[1]\n","          test.loc[i] = [label, sentence]\n","          i = i + 1\n","\n","        print(test)\n","\n","\n","        #Train데이터 생성하기\n","        trainSet = trainADS + trainCDS\n","\n","        train = pd.DataFrame(columns=('Label', 'Sentence'))\n","        i = 0\n","        for content in trainSet:\n","          infos = content.split(\",\")\n","          label = int(infos[0])\n","          sentence = infos[1]\n","          train.loc[i] = [label, sentence]\n","          i = i + 1\n","\n","        print(train)\n","\n","\n","        # 리뷰 문장 추출\n","        sentences = train['Sentence']\n","\n","        # BERT의 입력 형식에 맞게 변환\n","        sentences = [\"[CLS] \" + str(sentence) + \" [SEP]\" for sentence in sentences]\n","\n","        # 라벨 추출\n","        labels = train['Label'].values\n","        labels_re = []\n","        for label in labels:\n","          labels_re.append(label)\n","        labels = labels_re\n","\n","\n","\n","\n","\n","\n","\n","        tokenizer = KoBertTokenizer.from_pretrained('monologg/kobert')\n","\n","        print(\"Before patching: \",len(tokenizer.get_vocab()))\n","\n","        # CHILDES데이터 사용하여 사전학습 모델 튜닝\n","        entireCorpus = \"../../Data/CHILDES/CHILDES_all_spellchecked_corrected.txt\"\n","        entireFr = open(entireCorpus, 'r')\n","        entireContents = entireFr.readlines()\n","        entireFr.close()\n","\n","        import re\n","\n","        entireSet = set()\n","        entireContentList = list()\n","        #공백을 기준으로 단어를 생성하고 추가하기\n","        for entireContent in entireContents:\n","          entireContent = re.sub('[^가-힣]', ' ', entireContent)\n","          entireContent = re.sub('[\\s]+', ' ', entireContent)\n","          entireContentList.append(entireContent.replace(\"\\n\",\"\"))\n","          entireContentSplit = entireContent.split(\" \")\n","          for each in entireContentSplit:\n","            if each != \"\":\n","              entireSet.add(each)\n","\n","        # print(len(entireSet)) #37898\n","        wordDic = {}\n","        for eachWord in entireSet:\n","          wordDic[eachWord] = 0\n","\n","        for contentEach in entireContentList:\n","          contentEachSplit = contentEach.split(\" \")\n","          for each in contentEachSplit:\n","            if each != \"\":\n","              wordDic[each] = wordDic[each] + 1\n","\n","        wordDicSorted = dict(sorted(wordDic.items(), key=lambda x: x[1], reverse=True))\n","\n","        #사전에 추가하기\n","        countNum = 1\n","        for key, value in wordDicSorted.items():\n","          if value > 1:\n","            countNum = countNum + 1\n","            tokenizer.add_tokens([key])\n","\n","        # print(countNum) #3630\n","\n","        print(\"After patching: \",len(tokenizer.get_vocab()))\n","\n","        # BERT의 토크나이저로 문장을 토큰으로 분리\n","        tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]\n","\n","        # 입력 토큰의 최대 시퀀스 길이\n","        MAX_LEN = currentMaxLength\n","\n","        # 토큰을 숫자 인덱스로 변환\n","        input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n","\n","        # 문장을 MAX_LEN 길이에 맞게 자르고, 모자란 부분을 패딩 0으로 채움\n","        input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n","\n","        # 어텐션 마스크 초기화\n","        attention_masks = []\n","\n","        # 어텐션 마스크를 패딩이 아니면 1, 패딩이면 0으로 설정\n","        # 패딩 부분은 BERT 모델에서 어텐션을 수행하지 않아 속도 향상\n","        for seq in input_ids:\n","          seq_mask = [float(i>0) for i in seq]\n","          attention_masks.append(seq_mask)\n","\n","        print(attention_masks[0])\n","        print(labels)\n","        print(input_ids)\n","\n","\n","        # 훈련셋과 검증셋으로 분리\n","        train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids,\n","                                                                                            labels,\n","                                                                                            random_state=2018,\n","                                                                                            test_size=0.1)\n","\n","        # 어텐션 마스크를 훈련셋과 검증셋으로 분리\n","        train_masks, validation_masks, _, _ = train_test_split(attention_masks,\n","                                                              input_ids,\n","                                                              random_state=2018,\n","                                                              test_size=0.1)\n","\n","        # 데이터를 파이토치의 텐서로 변환\n","        train_inputs = torch.tensor(train_inputs)\n","        train_labels = torch.tensor(train_labels)\n","        train_masks = torch.tensor(train_masks)\n","        validation_inputs = torch.tensor(validation_inputs)\n","        validation_labels = torch.tensor(validation_labels)\n","        validation_masks = torch.tensor(validation_masks)\n","\n","        # 배치 사이즈\n","        batch_size = currentBatch\n","\n","        # 파이토치의 DataLoader로 입력, 마스크, 라벨을 묶어 데이터 설정\n","        # 학습시 배치 사이즈 만큼 데이터를 가져옴\n","        train_data = TensorDataset(train_inputs, train_masks, train_labels)\n","        train_sampler = RandomSampler(train_data)\n","        train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n","\n","        validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n","        validation_sampler = SequentialSampler(validation_data)\n","        validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)\n","\n","        # 분류를 위한 BERT 모델 생성\n","        model = BertForSequenceClassification.from_pretrained(\"monologg/kobert\", num_labels=labelNumber)\n","        model.cuda()\n","\n","        model.resize_token_embeddings(len(tokenizer.get_vocab()))\n","\n","        # 정확도 계산 함수\n","        def flat_accuracy(preds, labels):\n","          pred_flat = np.argmax(preds, axis=1).flatten()\n","          labels_flat = labels.flatten()\n","\n","          return np.sum(pred_flat == labels_flat) / len(labels_flat)\n","\n","        # 시간 표시 함수\n","        def format_time(elapsed):\n","          # 반올림\n","          elapsed_rounded = int(round((elapsed)))\n","\n","          # hh:mm:ss으로 형태 변경\n","          return str(datetime.timedelta(seconds=elapsed_rounded))\n","\n","        # 입력 데이터 변환\n","        def convert_input_data(sentences):\n","          # BERT의 토크나이저로 문장을 토큰으로 분리\n","          tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]\n","\n","          # 입력 토큰의 최대 시퀀스 길이\n","          MAX_LEN = currentMaxLength\n","\n","          # 토큰을 숫자 인덱스로 변환\n","          input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n","\n","          # 문장을 MAX_LEN 길이에 맞게 자르고, 모자란 부분을 패딩 0으로 채움\n","          input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n","\n","          # 어텐션 마스크 초기화\n","          attention_masks = []\n","\n","          # 어텐션 마스크를 패딩이 아니면 1, 패딩이면 0으로 설정\n","          # 패딩 부분은 BERT 모델에서 어텐션을 수행하지 않아 속도 향상\n","          for seq in input_ids:\n","            seq_mask = [float(i>0) for i in seq]\n","            attention_masks.append(seq_mask)\n","\n","          # 데이터를 파이토치의 텐서로 변환\n","          inputs = torch.tensor(input_ids)\n","          masks = torch.tensor(attention_masks)\n","\n","          return inputs, masks\n","\n","        ##############################결과구문으로출력###################################\n","        def outreault(guess):\n","          guess = int(guess)\n","          outClass = \"\"\n","          if guess == 0:\n","              outClass = \"ADS\"\n","          elif guess == 1:\n","              outClass = \"CDS\"\n","\n","          return outClass\n","\n","\n","        # 옵티마이저 설정\n","        optimizer = AdamW(model.parameters(),\n","                          lr = currentLearningRate, # 학습률\n","                          eps = setEpsilon # 0으로 나누는 것을 방지하기 위한 epsilon 값\n","                        )\n","\n","        # 에폭수\n","        epochs = setEpoch\n","\n","        # 총 훈련 스텝 : 배치반복 횟수 * 에폭\n","        total_steps = len(train_dataloader) * epochs\n","\n","        # 학습률을 조금씩 감소시키는 스케줄러 생성\n","        scheduler = get_linear_schedule_with_warmup(optimizer,\n","                                                    num_warmup_steps = 0,\n","                                                    num_training_steps = total_steps)\n","\n","\n","        #학습\n","        # 재현을 위해 랜덤시드 고정\n","        seed_val = setSeed\n","        random.seed(seed_val)\n","        np.random.seed(seed_val)\n","        torch.manual_seed(seed_val)\n","        torch.cuda.manual_seed_all(seed_val)\n","\n","        # 그래디언트 초기화\n","        model.zero_grad()\n","\n","\n","        outDir = \"../../Output/BERT/bert_ADSCDS_LR_\"+str(currentLearningRate) + \"_Batch_\" + str(currentBatch) + \"_SL_\" + str(currentMaxLength) + \"_trial_\" +str(currentTry)+\".csv\"\n","        f = open(outDir, 'w')\n","        f.write(\"epoch,trainingTime,trainingLoss,sentence,originalLabel,predictedLabel,predictedClass,result\"+\"\\n\")\n","\n","        # 에폭만큼 반복\n","        for epoch_i in range(1, epochs + 1):\n","\n","\n","\n","          # ========================================\n","          #               Training\n","          # ========================================\n","\n","          print(\"\")\n","          print('======== Epoch {:} / {:} ========'.format(epoch_i, epochs))\n","          print('Training...')\n","\n","          # 시작 시간 설정\n","          t0 = time.time()\n","\n","          # 로스 초기화\n","          total_loss = 0\n","\n","          # 훈련모드로 변경\n","          model.train()\n","\n","          # 데이터로더에서 배치만큼 반복하여 가져옴\n","          for step, batch in enumerate(train_dataloader):\n","            # 경과 정보 표시\n","            if step % 500 == 0 and not step == 0:\n","              elapsed = format_time(time.time() - t0)\n","              print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(tsrain_dataloader), elapsed))\n","\n","            # 배치를 GPU에 넣음\n","            batch = tuple(t.to(device) for t in batch)\n","\n","            # 배치에서 데이터 추출\n","            b_input_ids, b_input_mask, b_labels = batch\n","\n","            # Forward 수행\n","            outputs = model(b_input_ids,\n","                            token_type_ids=None,\n","                            attention_mask=b_input_mask,\n","                            labels=b_labels)\n","\n","            # 로스 구함\n","            loss = outputs[0]\n","\n","            # 총 로스 계산\n","            total_loss += loss.item()\n","\n","            # Backward 수행으로 그래디언트 계산\n","            loss.backward()\n","\n","            # 그래디언트 클리핑\n","            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","\n","            # 그래디언트를 통해 가중치 파라미터 업데이트\n","            optimizer.step()\n","\n","            # 스케줄러로 학습률 감소\n","            scheduler.step()\n","\n","            # 그래디언트 초기화\n","            model.zero_grad()\n","\n","          # 평균 로스 계산\n","          avg_train_loss = total_loss / len(train_dataloader)\n","\n","          trainingLoss = str(avg_train_loss)\n","          trainingTime = str(format_time(time.time() - t0))\n","\n","          print(\"\")\n","          print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n","          print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\n","\n","          # ========================================\n","          #               Validation\n","          # ========================================\n","\n","          print(\"\")\n","          print(\"Running Validation...\")\n","\n","          #시작 시간 설정\n","          t0 = time.time()\n","\n","          # 평가모드로 변경\n","          model.eval()\n","\n","          # 변수 초기화\n","          eval_loss, eval_accuracy = 0, 0\n","          nb_eval_steps, nb_eval_examples = 0, 0\n","\n","          # 데이터로더에서 배치만큼 반복하여 가져옴\n","          for batch in validation_dataloader:\n","            # 배치를 GPU에 넣음\n","            batch = tuple(t.to(device) for t in batch)\n","\n","            # 배치에서 데이터 추출\n","            b_input_ids, b_input_mask, b_labels = batch\n","\n","            # 그래디언트 계산 안함\n","            with torch.no_grad():\n","                # Forward 수행\n","                outputs = model(b_input_ids,\n","                                token_type_ids=None,\n","                                attention_mask=b_input_mask)\n","\n","            # 로스 구함\n","            logits = outputs[0]\n","\n","            # CPU로 데이터 이동\n","            logits = logits.detach().cpu().numpy()\n","            label_ids = b_labels.to('cpu').numpy()\n","\n","            # 출력 로짓과 라벨을 비교하여 정확도 계산\n","            tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n","            eval_accuracy += tmp_eval_accuracy\n","            nb_eval_steps += 1\n","\n","\n","\n","          print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n","          print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n","\n","          # ###############################전체 모델 성능 평가########################################\n","\n","          # 문장 테스트\n","          def test_sentences(sentences):\n","            # 평가모드로 변경\n","            model.eval()\n","\n","            # 문장을 입력 데이터로 변환\n","            inputs, masks = convert_input_data(sentences)\n","\n","            # 데이터를 GPU에 넣음\n","            b_input_ids = inputs.to(device)\n","            b_input_mask = masks.to(device)\n","\n","            # 그래디언트 계산 안함\n","            with torch.no_grad():\n","                # Forward 수행\n","                outputs = model(b_input_ids,\n","                                token_type_ids=None,\n","                                attention_mask=b_input_mask)\n","\n","            # 로스 구함\n","            logits = outputs[0]\n","\n","            # CPU로 데이터 이동\n","            logits = logits.detach().cpu().numpy()\n","\n","            return logits\n","\n","          # 리뷰 문장 추출\n","          testSentences = test['Sentence']\n","\n","          totalNum = 0\n","          correctNum = 0\n","          for each in range(0, len(testSentences)):\n","            logits = test_sentences([test['Sentence'][each]])\n","            guess = str(np.argmax(logits))\n","            print(guess,test['Label'][each],test['Sentence'][each])\n","            if guess == str(test['Label'][each]):\n","                f.write(str(epoch_i) + \",\" + trainingTime + \",\" + trainingLoss + \",\" + test['Sentence'][each] + \",\" + str(test['Label'][each]) + \",\" + guess + \",\" + outreault(guess)+ \",1\" + \"\\n\")\n","                correctNum = correctNum + 1\n","            else:\n","                f.write(str(epoch_i) + \",\" + trainingTime + \",\" + trainingLoss + \",\" + test['Sentence'][each] + \",\" + str(test['Label'][each]) + \",\" + guess + \",\" + outreault(guess)+ \",0\" + \"\\n\")\n","            totalNum = totalNum + 1\n","\n","          print(\"totalNum: \", totalNum, \" correctNum: \", correctNum, \" accuracy: \", (correctNum/totalNum))\n","\n","        f.close()\n","\n","        print(\"\")\n","        print(\"LR_\"+str(currentLearningRate) + \"_Batch_\" + str(currentBatch) + \"_SL_\" + str(currentMaxLength) + \"_trial_\" +str(currentTry)+\"_Training complete!\")\n"],"metadata":{"id":"fZllViXQab7a","colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["9fed146e3e6f449795c1b4ada8937b65","fbd7ef10600243769cf649e5998aa042","dae0ae3edb87414199336bc66efe2b9f","3fd3174160d54618bb6a9eac1a8cf065","2f1a105df2ac4268bdca1ad394263d42","a2c60877d66e42a3b84154c625d3bd18","c1c6ea4be0e74440bf01cebf59bd9936","a084df3445e14c73bd87b9f5d09183c2","e933229286b44cf380f2d6b799cc71b1","0d2f95582a94432da0ecda7bc02cbb96","a760cd48d94f4da39226bead900b23ee","82170a539c114485b1b6eb20fe20e27b","feef82886dcf448a9c5e33b078a6c40f","82b84e35c9e641708cae6bcffdb3b551","f8aab7d9c4374897913a9977dabc51b8","54825f9a42824179aaec4fccb293c4de","88a882014e3945df9d9648518ff0e473","9abaafec3d9e464586fc1bbc33a77425","ffda63d9bd724bb58df14b4d31a61e38","2d06b5359c4f4c298af56b7e5cba29f1","21649ad75ae0430cab79dca491df9c30","2dedfe9f115a4c89b6857c928cb97f07","25c4b2f5a3584acf9478000c4ba9aa09","35d5862c297f43da874b13e6e217f237","0630bdb0daf54fcb9f9dd6b8c3431365","690183cd85c24aa2b07a73dea2719f18","f47b1d1e59f14c8aaa9c6b5f2c01fd57","eb458838272e4a868d767cc02983131f","a94d7d3b5a3c4713875f682ea4809de0","e73d3a01810a4675bfbbf857ec0bbcfd","91a04c9b76fa49399329ae84d792e05b","ad429c9685da4abb944d00fba160053a","5d118e4fe9a2461b817d553985d16745","c13e0c66ea144a23a535ad875b64584a","f885b0ea40e641c9bab909abcecb921e","3dcc14a080c84bc5826812ef8e57d04c","25abd1d937ce4a15b7090b9106571640","3b83e6ee8a1142eb8c11635e79b6fba5","17969b187c924957b817b132c47aea01","557f8737e80a4d23aadbe995b39f554e","e57caedbd4da489e966d044cc516a25c","9347e85c45c644619a6a094b3371728d","aeb99cd7b5974ac5aacf85b09fed17c8","7de806da3db449a99679b0a7e311a765","bf2fcb0b23f74871b15f7134824e5092","a081636ab6074898be3365a2fb442ec5","dce2aa48fc2141f4bd109c42927eb673","fbcf51736ddd49648a35e9111f020c3b","80065dd280b44475bfb606aa1d0829a4","1cbe0671738f4d2da20411f0c7b1f3d0","a52661fc69ed43d8abd6211b71dcbea4","90354e1d2dff4754a728d7bd6fed0554","1fafd8dcf5cd4791b8ea0d85eb3c1e0c","a44fdf2dd6294447b2bdaa90e27fdb0b","66fa54fd03e343408df83def7fe39f51"],"output_embedded_package_id":"1gOg0CTcrrRORHBUUh73IBMW4EpMNO5dt"},"outputId":"fa86ac06-d9db-4c91-db8a-4e43f9baf778","executionInfo":{"status":"error","timestamp":1682346758078,"user_tz":-540,"elapsed":36067801,"user":{"displayName":"Seongmin Mun","userId":"17295717412647902050"}}},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]}]}