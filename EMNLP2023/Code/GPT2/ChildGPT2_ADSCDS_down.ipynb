{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"provenance":[],"gpuType":"T4","gpuClass":"premium"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.1"},"gpuClass":"premium","widgets":{"application/vnd.jupyter.widget-state+json":{"888a4d1b95624b98a910ce34507d53a1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_01525fd4c014478baa1150db3ce51394","IPY_MODEL_aa8d6eed84f545ae802e375b8cb5196b","IPY_MODEL_93683aa2150b4e8d832d68d1f016fd31"],"layout":"IPY_MODEL_c3113e32a9df410285c9f2e2b3a70d8e"}},"01525fd4c014478baa1150db3ce51394":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_108c84dd58da4808a0b86f21225ca493","placeholder":"​","style":"IPY_MODEL_a21c3c169f9849ab8d6920d4fa0e47cc","value":"Downloading (…)lve/main/config.json: 100%"}},"aa8d6eed84f545ae802e375b8cb5196b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_44cb0048284a43b388273ed9dfa83be2","max":1000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_acf1339dd6974e5d95f1f110a10b9da7","value":1000}},"93683aa2150b4e8d832d68d1f016fd31":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9bee788df13042e4bcc6e6e8719c1809","placeholder":"​","style":"IPY_MODEL_9f0ed7acaf5e4e929f9633e291b1ff54","value":" 1.00k/1.00k [00:00&lt;00:00, 77.1kB/s]"}},"c3113e32a9df410285c9f2e2b3a70d8e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"108c84dd58da4808a0b86f21225ca493":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a21c3c169f9849ab8d6920d4fa0e47cc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"44cb0048284a43b388273ed9dfa83be2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"acf1339dd6974e5d95f1f110a10b9da7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9bee788df13042e4bcc6e6e8719c1809":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9f0ed7acaf5e4e929f9633e291b1ff54":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d616ee35d0f04429bb13ceac9f9b570d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3a6bb7c80a074627a9c9ebd016a8e31e","IPY_MODEL_df401f9d6c48466b91faaea31f0d776a","IPY_MODEL_82cbb5ff751545c49587928ed4a3af57"],"layout":"IPY_MODEL_d55127a5a9e647649d0e131288c4591c"}},"3a6bb7c80a074627a9c9ebd016a8e31e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_41c800fd5af74f54972013e1b4fc76a7","placeholder":"​","style":"IPY_MODEL_e658807525174275b7808b8c6c8250b2","value":"Downloading pytorch_model.bin: 100%"}},"df401f9d6c48466b91faaea31f0d776a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_45779b3051a84a45a292f635fad88354","max":513302779,"min":0,"orientation":"horizontal","style":"IPY_MODEL_747280bcf5d74d3498812a9b6bf0eaa8","value":513302779}},"82cbb5ff751545c49587928ed4a3af57":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_36af8844b0f84934b1621bcfdfe0fa75","placeholder":"​","style":"IPY_MODEL_475f14becbc446f0b88921f3f85d581f","value":" 513M/513M [00:00&lt;00:00, 576MB/s]"}},"d55127a5a9e647649d0e131288c4591c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"41c800fd5af74f54972013e1b4fc76a7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e658807525174275b7808b8c6c8250b2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"45779b3051a84a45a292f635fad88354":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"747280bcf5d74d3498812a9b6bf0eaa8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"36af8844b0f84934b1621bcfdfe0fa75":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"475f14becbc446f0b88921f3f85d581f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d3e53f929e6e481c97b69974b176dc96":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_04d02dc1d096413f95e74e541d64595e","IPY_MODEL_c347842e85384329a7b2859ef90e130f","IPY_MODEL_b6d9738e5fc141c5bf0e726201c8c153"],"layout":"IPY_MODEL_f6a769de8a5344a694303f90ee64697d"}},"04d02dc1d096413f95e74e541d64595e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2c48f7779fd44eedb94ec18f6ed0779f","placeholder":"​","style":"IPY_MODEL_32894eae3b8249d69960784e40c562e5","value":"Downloading (…)/main/tokenizer.json: 100%"}},"c347842e85384329a7b2859ef90e130f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8bb41443db694a2086c1768c4bb1fc06","max":2825034,"min":0,"orientation":"horizontal","style":"IPY_MODEL_21270ea0f22542ab86fc955c6903f48b","value":2825034}},"b6d9738e5fc141c5bf0e726201c8c153":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d2dece3bfa9c4c5eb9b1ca8cb0b4ed1a","placeholder":"​","style":"IPY_MODEL_d5328fb9b5f64a55ba5e9fad92ad0c99","value":" 2.83M/2.83M [00:01&lt;00:00, 2.26MB/s]"}},"f6a769de8a5344a694303f90ee64697d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2c48f7779fd44eedb94ec18f6ed0779f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"32894eae3b8249d69960784e40c562e5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8bb41443db694a2086c1768c4bb1fc06":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"21270ea0f22542ab86fc955c6903f48b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d2dece3bfa9c4c5eb9b1ca8cb0b4ed1a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d5328fb9b5f64a55ba5e9fad92ad0c99":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"cFEpHz9q2TkF"},"source":["# ChildGPT-2_ADSCDS"]},{"cell_type":"code","metadata":{"id":"li9QWpubgHQ4"},"source":["##Parameter setting\n","setEpoch = 30\n","setLearningRate = [0.001, 0.0005, 0.0001]\n","setBatch = [16, 32, 64]\n","setMaxLength = [64, 128, 256]\n","setEpsilon = 1e-8\n","setSeed = 42\n","labelNumber = 2\n","setTry = 4"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import tensorflow as tf\n","\n","# Get the GPU device name.\n","device_name = tf.test.gpu_device_name()\n","\n","# The device name should look like the following:\n","if device_name == '/device:GPU:0':\n","    print('Found GPU at: {}'.format(device_name))\n","else:\n","    raise SystemError('GPU device not found')\n","import torch\n","\n","# If there's a GPU available...\n","if torch.cuda.is_available():\n","\n","    # Tell PyTorch to use the GPU.\n","    device = torch.device(\"cuda\")\n","\n","    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n","\n","    print('We will use the GPU:', torch.cuda.get_device_name(0))\n","\n","# If not...\n","else:\n","    print('No GPU available, using the CPU instead.')\n","    device = torch.device(\"cpu\")"],"metadata":{"id":"uBZ5Y6ycoSWz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Mount Google Drive to this Notebook instance.\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zRUkZTKNa7xk","executionInfo":{"status":"ok","timestamp":1683185073460,"user_tz":-540,"elapsed":24366,"user":{"displayName":"Seongmin Mun","userId":"17295717412647902050"}},"outputId":"72d7eaca-f2f5-4eb9-9fcd-e8cff363d1fe"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SEAoJWbt2TkL","executionInfo":{"status":"ok","timestamp":1683185087739,"user_tz":-540,"elapsed":10413,"user":{"displayName":"Seongmin Mun","userId":"17295717412647902050"}},"outputId":"938fd7a7-f471-4587-9c8e-b23117459d90"},"source":["!pip install transformers\n","!pip install keras_preprocessing"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.28.1-py3-none-any.whl (7.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m103.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n","Collecting huggingface-hub<1.0,>=0.11.0\n","  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n","  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m118.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (2023.4.0)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n","Installing collected packages: tokenizers, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.14.1 tokenizers-0.13.3 transformers-4.28.1\n"]}]},{"cell_type":"code","metadata":{"id":"Hv2_wH8A2TkN"},"source":["import tensorflow as tf\n","import torch\n","\n","from transformers import BertTokenizer\n","from transformers import BertForSequenceClassification, AdamW, BertConfig\n","from transformers import get_linear_schedule_with_warmup\n","from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n","# from keras.preprocessing.sequence import pad_sequences\n","from keras_preprocessing.sequence import pad_sequences\n","from sklearn.model_selection import train_test_split\n","\n","import pandas as pd\n","import numpy as np\n","import random\n","import time\n","import datetime"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","\n","# 본격적인 학습 시작\n","for currentLearningRate in setLearningRate:\n","  for currentBatch in setBatch:\n","    for currentMaxLength in setMaxLength:\n","      for currentTry in range(1,setTry):\n","\n","\n","        # 1. Model and Tokenizer\n","        # https://github.com/SKT-AI/KoGPT2\n","        from transformers import set_seed, GPT2LMHeadModel, PreTrainedTokenizerFast, GPT2ForSequenceClassification, GPT2Config\n","\n","        set_seed(731)\n","        model_config = GPT2Config.from_pretrained('skt/kogpt2-base-v2', num_labels=labelNumber) # Binary Classification\n","        model = GPT2ForSequenceClassification.from_pretrained('skt/kogpt2-base-v2', config=model_config)\n","\n","        tokenizer = PreTrainedTokenizerFast.from_pretrained(\"skt/kogpt2-base-v2\",\n","          bos_token='</s>', eos_token='</s>', unk_token='<unk>',\n","          pad_token='<pad>', mask_token='<mask>')\n","        tokenizer.padding_side = \"left\" # Very Important\n","        tokenizer.pad_token = tokenizer.eos_token\n","\n","        print(\"Before patching: \",len(tokenizer.get_vocab()))\n","\n","        # CHILDES데이터 사용하여 사전학습 모델 튜닝\n","        entireCorpus = \"../../Data/CHILDES/CHILDES_all_spellchecked_corrected.txt\"\n","        entireFr = open(entireCorpus, 'r')\n","        entireContents = entireFr.readlines()\n","        entireFr.close()\n","\n","        import re\n","\n","        entireSet = set()\n","        entireContentList = list()\n","        #공백을 기준으로 단어를 생성하고 추가하기\n","        for entireContent in entireContents:\n","            entireContent = re.sub('[^가-힣]', ' ', entireContent)\n","            entireContent = re.sub('[\\s]+', ' ', entireContent)\n","            entireContentList.append(entireContent.replace(\"\\n\",\"\"))\n","\n","            entireContentSplit = entireContent.split(\" \")\n","            for each in entireContentSplit:\n","              if each != \"\":\n","                entireSet.add(each)\n","\n","        # print(len(entireSet)) #37898\n","        wordDic = {}\n","        for eachWord in entireSet:\n","          wordDic[eachWord] = 0\n","\n","        for contentEach in entireContentList:\n","          contentEachSplit = contentEach.split(\" \")\n","          for each in contentEachSplit:\n","            if each != \"\":\n","              wordDic[each] = wordDic[each] + 1\n","\n","        wordDicSorted = dict(sorted(wordDic.items(), key=lambda x: x[1], reverse=True))\n","\n","        #사전에 추가하기\n","        countNum = 1\n","        for key, value in wordDicSorted.items():\n","          if value > 1:\n","            countNum = countNum + 1\n","            tokenizer.add_tokens([key])\n","\n","        print(\"After patching: \",len(tokenizer.get_vocab()))\n","\n","        model.resize_token_embeddings(len(tokenizer))\n","        model.config.pad_token_id = model.config.eos_token_id\n","\n","        #2. Build Dataset\n","        import os\n","        import pandas as pd\n","        from torch.utils.data import Dataset\n","\n","        class Dataset(Dataset):\n","            def __init__(self, train=True):\n","                super().__init__()\n","                self.train = train\n","                self.data = pd.read_csv(os.path.join(\"../../Data/RandomSelectedData/\", \"train_\"+str(currentTry)+\".csv\" if train else \"test_\"+str(currentTry)+\".csv\"))\n","\n","            def __len__(self):\n","                return len(self.data)\n","\n","            def __getitem__(self, index):\n","                record = self.data.iloc[index]\n","                text = record['Sentence']\n","                if self.train:\n","                    return {'Sentence': text, 'label': record['Label']}\n","                else:\n","                    return {'Sentence': text, 'label': '0'}\n","\n","        train_dataset = Dataset(train=True)\n","        test_dataset = Dataset(train=False)\n","        #3. Data Collator\n","        class Gpt2ClassificationCollator(object):\n","            def __init__(self, tokenizer, max_seq_len=None):\n","                self.tokenizer = tokenizer\n","                self.max_seq_len = max_seq_len\n","\n","                return\n","\n","            def __call__(self, sequences):\n","                texts = [sequence['Sentence'] for sequence in sequences]\n","                labels = [int(sequence['label']) for sequence in sequences]\n","                inputs = self.tokenizer(text=texts,\n","                                        return_tensors='pt',\n","                                        padding=True,\n","                                        truncation=True,\n","                                        max_length=self.max_seq_len)\n","                inputs.update({'labels': torch.tensor(labels)})\n","\n","                return inputs\n","\n","        gpt2classificationcollator = Gpt2ClassificationCollator(tokenizer=tokenizer,\n","                                                                max_seq_len=currentMaxLength)\n","\n","        #4. DataLoader\n","        from torch.utils.data import DataLoader, random_split\n","\n","        train_size = int(len(train_dataset) * 0.9)\n","        val_size = len(train_dataset) - train_size\n","        train_dataset, val_dataset = random_split(train_dataset, [train_size, val_size])\n","\n","        train_dataloader = DataLoader(dataset=train_dataset,\n","                                      batch_size=currentBatch,\n","                                      shuffle=True,\n","                                      collate_fn=gpt2classificationcollator)\n","        val_dataloader = DataLoader(dataset=val_dataset,\n","                                    batch_size=currentBatch,\n","                                    shuffle=False,\n","                                    collate_fn=gpt2classificationcollator)\n","        test_dataloader = DataLoader(dataset=test_dataset,\n","                                    batch_size=currentBatch,\n","                                    shuffle=False,\n","                                    collate_fn=gpt2classificationcollator)\n","\n","        #5. Optimizer & Lr Scheduler\n","        from transformers import AdamW, get_cosine_schedule_with_warmup\n","\n","        total_epochs = setEpoch\n","\n","        param_optimizer = list(model.named_parameters())\n","        no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n","        optimizer_grouped_parameters = [\n","            {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n","            {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n","        ]\n","        optimizer = AdamW(optimizer_grouped_parameters,\n","                          lr=currentLearningRate,\n","                          eps=setEpsilon)\n","\n","        num_train_steps = len(train_dataloader) * total_epochs\n","        num_warmup_steps = int(num_train_steps * 0.1)\n","\n","        lr_scheduler = get_cosine_schedule_with_warmup(optimizer,\n","                                                      num_warmup_steps=num_warmup_steps,\n","                                                      num_training_steps = num_train_steps)\n","\n","\n","        #6. Train & Validation\n","        import torch\n","\n","        def train(dataloader, optimizer, scheduler, device_):\n","            global model\n","            model.train()\n","\n","            prediction_labels = []\n","            true_labels = []\n","\n","            total_loss = []\n","\n","            for batch in dataloader:\n","                true_labels += batch['labels'].numpy().flatten().tolist()\n","                batch = {k:v.type(torch.long).to(device_) for k, v in batch.items()}\n","\n","\n","                outputs = model(**batch)\n","                loss, logits = outputs[:2]\n","                logits = logits.detach().cpu().numpy()\n","                total_loss.append(loss.item())\n","\n","                optimizer.zero_grad()\n","                loss.backward()\n","                torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0) # prevent exploding gradient\n","\n","                optimizer.step()\n","                scheduler.step()\n","\n","                prediction_labels += logits.argmax(axis=-1).flatten().tolist()\n","\n","            return true_labels, prediction_labels, total_loss\n","\n","        def validation(dataloader, device_):\n","            global model\n","            model.eval()\n","\n","            prediction_labels = []\n","            true_labels = []\n","\n","            embedding_outputs = []\n","\n","            total_loss = []\n","\n","            outputs = []\n","\n","            for batch in dataloader:\n","                true_labels += batch['labels'].numpy().flatten().tolist()\n","                batch = {k:v.type(torch.long).to(device_) for k, v in batch.items()}\n","\n","                with torch.no_grad():\n","                    outputs = model(**batch)\n","                    loss, logits = outputs[:2]\n","                    logits = logits.detach().cpu().numpy()\n","                    total_loss.append(loss.item())\n","\n","                    prediction_labels += logits.argmax(axis=-1).flatten().tolist()\n","\n","                    embedding_outputs += logits.tolist()\n","\n","                    outputs = outputs\n","\n","            return true_labels, prediction_labels, total_loss, outputs, embedding_outputs\n","\n","        ##############################결과구문으로출력###################################\n","        def outreault(guess):\n","            guess = int(guess)\n","            outConstruction = \"\"\n","            if guess == 0:\n","                outConstruction = \"ADS\"\n","            elif guess == 1:\n","                outConstruction = \"CDS\"\n","\n","            return outConstruction\n","\n","        #7. Run\n","\n","        outDir = \"../../Output/GPT2/gpt2_ADSCDS_LR_\"+str(currentLearningRate) + \"_Batch_\" + str(currentBatch) + \"_SL_\" + str(currentMaxLength) + \"_trial_\" +str(currentTry)+\".csv\"\n","        f = open(outDir, 'w')\n","        f.write(\"epoch,sentence,originalLabel,predictedLabel,predictedConstruction,result\"+\"\\n\")\n","\n","        from sklearn.metrics import classification_report, accuracy_score\n","\n","        device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","        model.to(device)\n","\n","        all_loss = {'train_loss': [], 'val_loss': []}\n","        all_acc = {'train_acc': [], 'val_acc': []}\n","        outputs = []\n","\n","        for epoch in range(total_epochs):\n","            y, y_pred, train_loss = train(train_dataloader, optimizer, lr_scheduler, device)\n","            train_acc = accuracy_score(y, y_pred)\n","\n","            y, y_pred, val_loss, outputs, logits_labels = validation(val_dataloader, device)\n","            val_acc = accuracy_score(y, y_pred)\n","\n","            all_loss['train_loss'] += train_loss\n","            all_loss['val_loss'] += val_loss\n","\n","            all_acc['train_acc'].append(train_acc)\n","            all_acc['val_acc'].append(val_acc)\n","\n","            outputs = outputs\n","\n","            print(\"\")\n","            print('======== Epoch {:} / {:} ========'.format(epoch + 1, total_epochs))\n","            print('Training...')\n","\n","            print(f'Epoch: {epoch}, train_loss: {torch.tensor(train_loss).mean():.3f}, train_acc: {train_acc:.3f}, val_loss: {torch.tensor(val_loss).mean():.3f}, val_acc: {val_acc:.3f}')\n","\n","            #if (epoch+1) == 1 or (epoch+1) == 2 or (epoch+1) == 3 or (epoch+1) == 4 or (epoch+1) == 5 or (epoch+1) == 6 or (epoch+1) == 7 or (epoch+1) == 8 or (epoch+1) == 9 or (epoch+1) == 10 :#or (epoch+1) == 20 or (epoch+1) == 30:# or (epoch+1) == 40 or (epoch+1) == 50:\n","            # ###############################전체 모델 성능 평가########################################\n","            y, y_pred, val_loss, outputs, logits_labels = validation(test_dataloader, device)\n","            import pandas as pd\n","\n","            testFileDir = fileDir = \"../../Data/RandomSelectedData/test_\"+str(currentTry)+\".csv\"\n","            testFr = open(testFileDir, 'r')\n","            testContents = testFr.readlines()\n","            testFr.close()\n","\n","            test = pd.DataFrame(columns=('Label', 'Sentence'))\n","            i = 0\n","            for content in testContents:\n","                if i == 0:\n","                    pass\n","                else:\n","                    infos = content.split(\",\")\n","                    label = int(infos[0])\n","                    sentence = infos[1].replace(\"\\n\", \"\")\n","                    test.loc[i] = [label, sentence]\n","                i = i + 1\n","\n","            test['Sentence'] = test['Sentence'].str.replace(r'[-=+,#/\\?:^$.@*\\\"※~&%ㆍ!』\\\\‘|\\(\\)\\[\\]\\<\\>`\\'…》\\\\n\\t]+', \" \", regex=True)\n","            test['Sentence'] = test['Sentence'].str.replace(r'\\t+', \" \", regex=True)\n","            test['Sentence'] = test['Sentence'].str.replace(r'[\\\\n]+', \" \", regex=True)\n","\n","            # 리뷰 문장 추출\n","            testSentences = test['Sentence']\n","\n","            totalNum = 0\n","            correctNum = 0\n","            for each in range(0, len(testSentences)):\n","                print(test['Label'][each + 1], test['Sentence'][each + 1])\n","                print(\"y_pred\", len(y_pred))\n","                guess = str(y_pred[each])\n","                if guess == str(test['Label'][each + 1]):\n","                    print(\"input: \", test['Sentence'][each + 1], \", predict: \", guess, \"(O)\")\n","                    f.write(str(epoch+1) + \",\" + test['Sentence'][each + 1] + \",\" + str(test['Label'][each + 1]) + \",\" + guess + \",\" + outreault(guess)+ \",1\" + \"\\n\")\n","                    correctNum = correctNum + 1\n","                else:\n","                    f.write(str(epoch+1) + \",\" + test['Sentence'][each + 1] + \",\" + str(test['Label'][each + 1]) + \",\" + guess + \",\" + outreault(guess) + \",0\" + \"\\n\")\n","                    print(\"input: \", test['Sentence'][each + 1], \", predict: \", guess, \"(X)\")\n","                totalNum = totalNum + 1\n","\n","            print(\"totalNum: \", totalNum, \" correctNum: \", correctNum, \" accuracy: \", (correctNum/totalNum))\n","\n","        f.close()\n","\n","        print(\"\")\n","        print(\"Training complete!\")"],"metadata":{"id":"YnGhc1CZafnJ","colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["888a4d1b95624b98a910ce34507d53a1","01525fd4c014478baa1150db3ce51394","aa8d6eed84f545ae802e375b8cb5196b","93683aa2150b4e8d832d68d1f016fd31","c3113e32a9df410285c9f2e2b3a70d8e","108c84dd58da4808a0b86f21225ca493","a21c3c169f9849ab8d6920d4fa0e47cc","44cb0048284a43b388273ed9dfa83be2","acf1339dd6974e5d95f1f110a10b9da7","9bee788df13042e4bcc6e6e8719c1809","9f0ed7acaf5e4e929f9633e291b1ff54","d616ee35d0f04429bb13ceac9f9b570d","3a6bb7c80a074627a9c9ebd016a8e31e","df401f9d6c48466b91faaea31f0d776a","82cbb5ff751545c49587928ed4a3af57","d55127a5a9e647649d0e131288c4591c","41c800fd5af74f54972013e1b4fc76a7","e658807525174275b7808b8c6c8250b2","45779b3051a84a45a292f635fad88354","747280bcf5d74d3498812a9b6bf0eaa8","36af8844b0f84934b1621bcfdfe0fa75","475f14becbc446f0b88921f3f85d581f","d3e53f929e6e481c97b69974b176dc96","04d02dc1d096413f95e74e541d64595e","c347842e85384329a7b2859ef90e130f","b6d9738e5fc141c5bf0e726201c8c153","f6a769de8a5344a694303f90ee64697d","2c48f7779fd44eedb94ec18f6ed0779f","32894eae3b8249d69960784e40c562e5","8bb41443db694a2086c1768c4bb1fc06","21270ea0f22542ab86fc955c6903f48b","d2dece3bfa9c4c5eb9b1ca8cb0b4ed1a","d5328fb9b5f64a55ba5e9fad92ad0c99"],"output_embedded_package_id":"1167nJLowbPnOWR0TM9uMMPTbB9BvZRCL"},"executionInfo":{"status":"error","timestamp":1683221102859,"user_tz":-540,"elapsed":35993261,"user":{"displayName":"Seongmin Mun","userId":"17295717412647902050"}},"outputId":"93b82b8f-7632-4963-b4e2-79d636e7bd36"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]}]}